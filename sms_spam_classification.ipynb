{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed78ed59",
   "metadata": {},
   "source": [
    "# Classification des SMS (Spam / Ham)\n",
    "\n",
    "              \n",
    "**Date :** 11 decembre 2025\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82bf3a0",
   "metadata": {},
   "source": [
    "## 1. Contexte & Données\n",
    "La croissance des échanges par SMS s’est accompagnée d’une hausse importante des messages indésirables (« spam »), qui perturbent les utilisateurs et peuvent représenter un risque de fraude. Le tri manuel étant impossible à grande échelle, il est essentiel de développer des systèmes automatiques capables d’identifier ces messages.\n",
    "Le dataset utilisé provient du SMS Spam Collection Dataset, composé de messages réels, dont 425 spams collectés manuellement sur le forum Grumbletext. Ces données textuelles brutes servent à entraîner un modèle de classification permettant de distinguer automatiquement les SMS « spam » des SMS « ham ».\n",
    "\n",
    "**Problématique**:\n",
    "\n",
    "L’augmentation des SMS indésirables pose plusieurs défis :\n",
    "\n",
    "Comment automatiser la détection des SMS spam afin de réduire la charge humaine ?\n",
    "\n",
    "Comment transformer le texte brut en représentations numériques exploitables pour la classification ?\n",
    "\n",
    "Dans un contexte où les messages sont courts, variés et bruités, comment réduire efficacement la dimensionnalité pour améliorer la performance du modèle ?\n",
    "\n",
    "Quel type de modèle de classification est le plus adapté pour distinguer brièvement un spam d’un ham ?\n",
    "\n",
    "Ces questions guident la démarche du projet.\n",
    "\n",
    "**Chemin d’accès**:\n",
    "\n",
    "Nom du fichier local : SMSSpamCollection\n",
    "\n",
    "Source officielle : UCI Machine Learning Repository\n",
    "\n",
    "Miroir accessible : Kaggle\n",
    "\n",
    "Type de fichier : texte tabulé (.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876eaaf3",
   "metadata": {},
   "source": [
    "## 1. Importation des Bibliotheques necessiares et des donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6f9f371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Charger les données\n",
    "df = pd.read_csv(\"SMSSpamCollection\", sep=\"\\t\", names=[\"label\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "606682c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taille du dataset\n",
    "print(df.shape)\n",
    "\n",
    "# Aperçu des premières lignes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14350f3",
   "metadata": {},
   "source": [
    "le dataset est constitue de 5572 lignes et 2 colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e60771e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Répartition des classes\n",
    "df[\"label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690ac8e0",
   "metadata": {},
   "source": [
    "## Répartition des classes (ham vs spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a190e2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHeCAYAAAB69RTiAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAARUpJREFUeJzt3Xl4jPf+//HXkIVYRixJpGKPrRFVKqIUtcZeWoqmdo49xaGqraVKaYviS7fTpijao9VTrVpKSzVC7Fs4tNZDrJGgaSJx//5Q989IkGiSSdzPx3XNdZnP/Z573vdke/ncm80wDEMAAAAWlsfZDQAAADgbgQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQi53p49e+Th4aE5c+Y4uxUAQC5FIEKOEB4eLpvNZj5cXFxUsmRJPf/88zp8+PBdX3flyhU9++yzGjp0qIYOHZqNHae2cuVKTZgwIc1lZcuWVc+ePc3np0+f1oQJE7Rr165UtRMmTJDNZsuaJh+QzWa767Y5U07tK7MtWLBAJUqU0JUrV8wxm82mIUOGOLErPKjr16+rQoUKmjVrlrNbwW0IRMhRPv30U23evFk//vijhgwZom+//Vb169dXbGxsmvV9+vRRnTp19NZbb2Vzp6mtXLlSEydOTHPZ8uXL9dprr5nPT58+rYkTJ6YZiPr27avNmzdnVZvIZf744w+98sorGjNmjAoVKuTsdpAJXF1d9frrr2vSpEm6ePGis9vBXwhEyFECAgJUt25dNWrUSOPGjdPLL7+sc+fO6Ztvvkmz/ssvv9SiRYucOqPyxx9/3LemZs2aqlChQrrWV6pUKdWtW/fvtoWHxGeffaaLFy+qb9++zm4Fmahr166y2Wz64IMPnN0K/kIgQo5Wu3ZtSdLZs2cdxrdt26Z27dqpaNGiypcvn2rWrKkvv/zSoebWbri1a9eqV69eKlq0qAoUKKC2bdvq999/d6hdu3at2rdvr1KlSilfvnyqWLGiBgwYoAsXLjjU3dqdtWPHDj377LPy9PRUhQoV1LNnT/3f//2fJDns+jt27Jgkx11mP//8s5544glJUq9evczaW7t+0tplduPGDU2fPl1VqlSRu7u7vLy89OKLL+rUqVMOdY0aNVJAQICioqLUoEEDeXh4qHz58nrrrbd048aN+37e8fHx6tevn4oVK6aCBQuqZcuW+u9//5tm7eHDh9WtWzd5eXnJ3d1dVatWNT+D2/uePHmyKleurPz586tIkSIKDAzUe++9d99eLl++rJEjR6p8+fLmNrdq1UoHDx6862vOnz+vQYMGqVq1aipYsKC8vLz09NNP65dffklVO3/+fNWoUUMFCxZUoUKFVKVKFb3yyivm8j/++EOjRo1SuXLllC9fPhUtWlS1a9fWkiVLHNaTnu/F9K4rLfPnz1fbtm1VpEiRNJcvXLhQVatWlYeHh2rUqKHvvvvOYfmRI0fUq1cv+fv7y8PDQ4888ojatm2rvXv3OtT9/PPPstlsWrx4scaMGaOSJUuqYMGCatu2rc6ePasrV66of//+Kl68uIoXL65evXrp6tWr9+w9LCxMBQoUUHx8fKplXbp0kbe3t65fvy5JWr9+vRo1aqRixYopf/78Kl26tDp16nTf/3Dc73XHjh2TzWbT9OnT9eabb6p06dLKly+fateurXXr1jnts3Jzc1OXLl304YcfyjCMe24jsoeLsxsA7uXo0aOSpEqVKpljP/30k1q2bKmgoCC9//77stvtWrp0qbp06aI//vjD4Vgd6eZutWbNmmnx4sU6efKkXn31VTVq1Eh79uwx/8j89ttvCg4OVt++fWW323Xs2DHNmDFD9evX1969e+Xq6uqwzo4dO+r555/XP/7xD127dk0BAQG6du2ali1b5rC7q2TJkqm26fHHH9enn36qXr166dVXX1Xr1q0l3ZwZupuBAwfqww8/1JAhQ9SmTRsdO3ZMr732mn7++Wft2LFDxYsXN2tjYmLUvXt3jRw5UuPHj9fy5cs1duxY+fr66sUXX7zrexiGoQ4dOigiIkKvv/66nnjiCf36668KCQlJVXvgwAHVq1dPpUuX1rvvvisfHx+tXr1aw4YN04ULFzR+/HhJ0vTp0zVhwgS9+uqreuqpp3T9+nUdPHhQly9fvmsf0s1jw+rXr69jx45pzJgxCgoK0tWrV7Vx40adOXNGVapUSfN1ly5dkiSNHz9ePj4+unr1qpYvX65GjRpp3bp1atSokSRp6dKlGjRokIYOHap33nlHefLk0ZEjR3TgwAFzXSNGjNDChQs1efJk1axZU9euXdO+ffscdnGk93sxPetKy6lTp7R3714NHDgwzeXff/+9oqKiNGnSJBUsWFDTp0/XM888o0OHDql8+fKSbu6eLVasmN566y2VKFFCly5d0meffaagoCDt3LlTlStXdljnK6+8osaNGys8PFzHjh3TqFGj1LVrV7m4uKhGjRpasmSJdu7cqVdeeUWFChXS7Nmz79p/79699d577+nLL790mOG6fPmy/vOf/2jw4MFydXXVsWPH1Lp1azVo0ECffPKJihQpov/9739atWqVkpKS5OHhkeb6M/K6uXPnqkyZMpo1a5b5H4yQkBBt2LBBwcHBTvmsGjVqpPnz52vfvn2qXr36XT9HZBMDyAE+/fRTQ5IRGRlpXL9+3bhy5YqxatUqw8fHx3jqqaeM69evm7VVqlQxatas6TBmGIbRpk0bo2TJkkZKSorDOp955hmHul9//dWQZEyePDnNXm7cuGFcv37dOH78uCHJ+M9//mMuGz9+vCHJeP3111O9bvDgwcbdfqTKlClj9OjRw3weFRVlSDI+/fTTVLW33uOW6OhoQ5IxaNAgh7otW7YYkoxXXnnFHGvYsKEhydiyZYtDbbVq1YwWLVqk2dstP/zwgyHJeO+99xzG33zzTUOSMX78eHOsRYsWRqlSpYy4uDiH2iFDhhj58uUzLl26ZBjGza/JY489ds/3TcukSZMMScbatWvvWXdnX3dKTk42rl+/bjRp0sTh+2DIkCFGkSJF7rnugIAAo0OHDvesSe/3YnrWlZYvvvjC/Lm4kyTD29vbiI+PN8diYmKMPHnyGFOnTr3rOpOTk42kpCTD39/feOmll8zxn376yZBktG3b1qE+LCzMkGQMGzbMYbxDhw5G0aJF77sNjz/+uFGvXj2HsXnz5hmSjL179xqGYRjLli0zJBm7du267/pul57XHT161JBk+Pr6GgkJCeZ4fHy8UbRoUaNp06Z3fW1Wf1aHDx82JBnz58+/77Yi67HLDDlK3bp15erqqkKFCqlly5by9PTUf/7zH7m43JzMPHLkiA4ePKju3btLkpKTk81Hq1atdObMGR06dMhhnbdqb6lXr57KlCmjn376yRw7d+6c/vGPf8jPz08uLi5ydXVVmTJlJEnR0dGp+uzUqVOmbve93OrzzpmvOnXqqGrVqqmm/X18fFSnTh2HscDAQB0/fjxd73Pn59WtWzeH53/++afWrVunZ555Rh4eHqm+Bn/++aciIyPNHnfv3q1BgwZp9erVae46ScsPP/ygSpUqqWnTpumqv93777+vxx9/XPny5TO/luvWrXP4OtapU0eXL19W165d9Z///CfVrtFbNT/88INefvll/fzzz0pISHBYnpHvxfut625Onz4tSfLy8kpzeePGjR0OtPb29paXl5fD1zo5OVlTpkxRtWrV5ObmJhcXF7m5uenw4cNpfm+3adPG4XnVqlUlyZzJvH380qVL991t1qtXL0VERDj8XH766ad64oknFBAQIEl67LHH5Obmpv79++uzzz5LtUv7bjLyuo4dOypfvnzm80KFCqlt27bauHGjUlJSJGX/Z3Xr6/q///0vXduLrEUgQo6yYMECRUVFaf369RowYICio6PVtWtXc/mtY4lGjRolV1dXh8egQYMkKdUfNx8fn1Tv4+PjY+6uuHHjhpo3b66vv/5ao0eP1rp167R161bzj3paf7zS2hWWVW71mdZ7+vr6ptrtUqxYsVR17u7u9/0jfPHiRbm4uKR6/Z2f38WLF5WcnKw5c+ak+hq0atVK0v//GowdO1bvvPOOIiMjFRISomLFiqlJkybatm3bPXs5f/78PXch3s2MGTM0cOBABQUF6auvvlJkZKSioqLUsmVLh+0PDQ3VJ598ouPHj6tTp07y8vJSUFCQ1q5da9bMnj1bY8aM0TfffKPGjRuraNGi6tChg3kZiIx8L95vXXdzq+fb/5DfLj1f6xEjRui1115Thw4dtGLFCm3ZskVRUVGqUaNGmt8TRYsWdXju5uZ2z/E///zzntvQvXt3ubu7Kzw8XNLN3a1RUVHq1auXWVOhQgX9+OOP8vLy0uDBg1WhQgVVqFDhvseaZeR1d/s9kJSUZAaV7P6sbn1d0xuQkbU4hgg5StWqVc0DqRs3bqyUlBR9/PHHWrZsmZ599lnzWJmxY8eqY8eOaa7jzv38MTExqWpiYmJUsWJFSdK+ffu0e/duhYeHq0ePHmbNkSNH7tpndp7VduuP3pkzZ1KFhNOnTzscP/R33yc5OVkXL150+EN75+fn6empvHnzKjQ0VIMHD05zXeXKlZMkubi4aMSIERoxYoQuX76sH3/8Ua+88opatGihkydP3vXYkBIlSqQ6YDw9Fi1aZB6Xcbvbr99zS69evdSrVy9du3ZNGzdu1Pjx49WmTRv997//VZkyZVSgQAFNnDhREydO1NmzZ80ZnrZt2+rgwYMZ+l6837ru5tZ7XLp06YFD+KJFi/Tiiy9qypQpDuMXLly464HamcnT01Pt27fXggULNHnyZH366afKly+fw390JKlBgwZq0KCBUlJStG3bNs2ZM0dhYWHy9vbW888/f9f1p/d1d/s94ObmpoIFC0rK/s/q1jFvmfUzjL+HGSLkaNOnT5enp6def/113bhxQ5UrV5a/v792796t2rVrp/m481otn3/+ucPziIgIHT9+3DzA9la4cXd3d6jL6Omwt16fnv/tZaT26aeflnTzl/XtoqKiFB0drSZNmmSoz7tp3LixpNSf1+LFix2ee3h4qHHjxtq5c6cCAwPT/BqkNXNRpEgRPfvssxo8eLAuXbpknoGXlpCQEP33v//V+vXrM7QNNpst1ddxz54997yuU4ECBRQSEqJx48YpKSlJ+/fvT1Xj7e2tnj17qmvXrjp06JD++OOPB/pevNu67ubWweO//fZbej+CVNL6TL7//vts3U3Tq1cvnT59WitXrtSiRYv0zDPP3DVg5M2bV0FBQeYZizt27EjXe9zvdV9//bXDDM2VK1e0YsUKNWjQQHnz5pWU/Z/VrV181apVy5L1I2OYIUKO5unpqbFjx2r06NFavHixXnjhBX3wwQcKCQlRixYt1LNnTz3yyCO6dOmSoqOjtWPHDv373/92WMe2bdvUt29fPffcczp58qTGjRunRx55xNytUaVKFVWoUEEvv/yyDMNQ0aJFtWLFCofdJ+lx6yyRadOmKSQkRHnz5lVgYKA5XX67ChUqKH/+/Pr8889VtWpVFSxYUL6+vvL19U1VW7lyZfXv319z5sxRnjx5FBISYp5l5ufnp5deeilDfd5N8+bN9dRTT2n06NG6du2aateurV9//VULFy5MVfvee++pfv36atCggQYOHKiyZcvqypUrOnLkiFasWGEGmbZt2yogIEC1a9dWiRIldPz4cc2aNUtlypSRv7//XXsJCwvTF198ofbt2+vll19WnTp1lJCQoA0bNqhNmzZmeLtTmzZt9MYbb2j8+PFq2LChDh06pEmTJqlcuXJKTk426/r166f8+fPrySefVMmSJRUTE6OpU6fKbrebl0QICgpSmzZtFBgYKE9PT0VHR2vhwoUKDg42Z7bS+72YnnWlJSgoSPnz51dkZKTatWt3n69g2tq0aaPw8HBVqVJFgYGB2r59u95+++0H2iX5oJo3b65SpUpp0KBBiomJcdhdJt087mv9+vVq3bq1SpcurT///FOffPKJJN3zOLKMvC5v3rxq1qyZRowYoRs3bmjatGmKj493uJhqdn9WkZGRyps3r5566qksWT8yyNlHdQOG8f/PCIuKikq1LCEhwShdurTh7+9vJCcnG4ZhGLt37zY6d+5seHl5Ga6uroaPj4/x9NNPG++//36qda5Zs8YIDQ01ihQpYuTPn99o1aqVcfjwYYf3OHDggNGsWTOjUKFChqenp/Hcc88ZJ06cSHUW060zwM6fP5+qz8TERKNv375GiRIlDJvNZkgyjh49ahhG6rPMDMMwlixZYlSpUsVwdXV1eJ87zzIzDMNISUkxpk2bZlSqVMlwdXU1ihcvbrzwwgvGyZMnHeoaNmxoPProo6l669Gjh1GmTJlU43e6fPmy0bt3b6NIkSKGh4eH0axZM+PgwYNpns119OhRo3fv3sYjjzxiuLq6GiVKlDDq1avncPbeu+++a9SrV88oXry44ebmZpQuXdro06ePcezYsfv2EhsbawwfPtwoXbq04erqanh5eRmtW7c2Dh48aNbc2VdiYqIxatQo45FHHjHy5ctnPP7448Y333yTavs/++wzo3Hjxoa3t7fh5uZm+Pr6Gp07dzb27Nlj1rz88stG7dq1DU9PT8Pd3d0oX7688dJLLxkXLlxw6DM934vpXVdaQkNDjWrVqqUal2QMHjw41fid32uxsbFGnz59DC8vL8PDw8OoX7++8csvvxgNGzY0GjZsaNbdOnPq3//+t8P67vazea+fhbS88sorhiTDz8/PPPvuls2bNxvPPPOMUaZMGcPd3d0oVqyY0bBhQ+Pbb7+95zrT87pbZ5lNmzbNmDhxolGqVCnDzc3NqFmzprF69WqH9WX3Z9WgQYNUZ6rBeWyGwRWh8HAKDw9Xr169FBUVZR6XBOQ227Zt0xNPPKHIyEgFBQU5u51c59ixYypXrpzefvttjRo1ytntmH777Tf5+/tr9erVatasmbPbgTiGCABytNq1a6tz58564403nN0KMtHkyZPVpEkTwlAOQiACgBzu3Xff1RNPPJHm2XLIfZKTk1WhQoVUt7qBc7HLDAAAWB4zRAAAwPIIRAAAwPIIRAAAwPK4MGM63bhxQ6dPn1ahQoWy9bYNAADgwRmGoStXrsjX11d58tx9HohAlE6nT5+Wn5+fs9sAAAAP4OTJk/e86rhTA9GECRMcLpsu3bzPz62b8BmGoYkTJ+rDDz9UbGyseZ+aRx991KxPTEzUqFGjtGTJEiUkJKhJkyaaN2+ew0bHxsZq2LBh+vbbbyVJ7dq105w5czJ0s75b9yQ6efKkChcu/KCbDAAAslF8fLz8/PzSvLfg7Zw+Q/Too4/qxx9/NJ/fusmedPPGnjNmzFB4eLgqVaqkyZMnq1mzZjp06JC5YWFhYVqxYoWWLl2qYsWKaeTIkWrTpo22b99urqtbt246deqUVq1aJUnq37+/QkNDtWLFinT3eWs3WeHChQlEAADkMvc73MXpgcjFxUU+Pj6pxg3D0KxZszRu3Dh17NhRkvTZZ5/J29tbixcv1oABAxQXF6d//etfWrhwoXkjv0WLFsnPz08//vijWrRooejoaK1atcrhsvcfffSRgoODdejQIVWuXDn7NhYAAORITj/L7PDhw/L19VW5cuX0/PPP6/fff5ckHT16VDExMWrevLlZ6+7uroYNGyoiIkKStH37dl2/ft2hxtfXVwEBAWbN5s2bZbfbHe4BVLduXdntdrMmLYmJiYqPj3d4AACAh5NTA1FQUJAWLFig1atX66OPPlJMTIzq1aunixcvmscReXt7O7zm9mOMYmJi5ObmJk9Pz3vWeHl5pXpvLy8vsyYtU6dOld1uNx8cUA0AwMPLqYEoJCREnTp1UvXq1dW0aVN9//33km7uGrvlzn1+hmHcdz/gnTVp1d9vPWPHjlVcXJz5OHnyZLq2CQAA5D5O32V2uwIFCqh69eo6fPiweVzRnbM4586dM2eNfHx8lJSUpNjY2HvWnD17NtV7nT9/PtXs0+3c3d3NA6g5kBoAgIdbjgpEiYmJio6OVsmSJVWuXDn5+Pho7dq15vKkpCRt2LBB9erVkyTVqlVLrq6uDjVnzpzRvn37zJrg4GDFxcVp69atZs2WLVsUFxdn1gAAAGtz6llmo0aNUtu2bVW6dGmdO3dOkydPVnx8vHr06CGbzaawsDBNmTJF/v7+8vf315QpU+Th4aFu3bpJkux2u/r06aORI0eqWLFiKlq0qEaNGmXugpOkqlWrqmXLlurXr58++OADSTdPu2/Tpg1nmAEAAElODkSnTp1S165ddeHCBZUoUUJ169ZVZGSkypQpI0kaPXq0EhISNGjQIPPCjGvWrHG4uNLMmTPl4uKizp07mxdmDA8Pd7ie0eeff65hw4aZZ6O1a9dOc+fOzd6NBQAAOZbNMAzD2U3kBvHx8bLb7YqLi+N4IgAAcon0/v3OUccQAQAAOAOBCAAAWB6BCAAAWB6BCAAAWB6BCAAAWB6BCAAAWJ5Tr0OE3KHsy987uwVko2NvtXZ2CwCQ7ZghAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlkcgAgAAlpdjAtHUqVNls9kUFhZmjhmGoQkTJsjX11f58+dXo0aNtH//fofXJSYmaujQoSpevLgKFCigdu3a6dSpUw41sbGxCg0Nld1ul91uV2hoqC5fvpwNWwUAAHKDHBGIoqKi9OGHHyowMNBhfPr06ZoxY4bmzp2rqKgo+fj4qFmzZrpy5YpZExYWpuXLl2vp0qXatGmTrl69qjZt2iglJcWs6datm3bt2qVVq1Zp1apV2rVrl0JDQ7Nt+wAAQM7m9EB09epVde/eXR999JE8PT3NccMwNGvWLI0bN04dO3ZUQECAPvvsM/3xxx9avHixJCkuLk7/+te/9O6776pp06aqWbOmFi1apL179+rHH3+UJEVHR2vVqlX6+OOPFRwcrODgYH300Uf67rvvdOjQIadsMwAAyFmcHogGDx6s1q1bq2nTpg7jR48eVUxMjJo3b26Oubu7q2HDhoqIiJAkbd++XdevX3eo8fX1VUBAgFmzefNm2e12BQUFmTV169aV3W43a9KSmJio+Ph4hwcAAHg4uTjzzZcuXaodO3YoKioq1bKYmBhJkre3t8O4t7e3jh8/bta4ubk5zCzdqrn1+piYGHl5eaVav5eXl1mTlqlTp2rixIkZ2yAAAJArOW2G6OTJkxo+fLgWLVqkfPny3bXOZrM5PDcMI9XYne6sSav+fusZO3as4uLizMfJkyfv+Z4AACD3clog2r59u86dO6datWrJxcVFLi4u2rBhg2bPni0XFxdzZujOWZxz586Zy3x8fJSUlKTY2Nh71pw9ezbV+58/fz7V7NPt3N3dVbhwYYcHAAB4ODktEDVp0kR79+7Vrl27zEft2rXVvXt37dq1S+XLl5ePj4/Wrl1rviYpKUkbNmxQvXr1JEm1atWSq6urQ82ZM2e0b98+syY4OFhxcXHaunWrWbNlyxbFxcWZNQAAwNqcdgxRoUKFFBAQ4DBWoEABFStWzBwPCwvTlClT5O/vL39/f02ZMkUeHh7q1q2bJMlut6tPnz4aOXKkihUrpqJFi2rUqFGqXr26eZB21apV1bJlS/Xr108ffPCBJKl///5q06aNKleunI1bDAAAciqnHlR9P6NHj1ZCQoIGDRqk2NhYBQUFac2aNSpUqJBZM3PmTLm4uKhz585KSEhQkyZNFB4errx585o1n3/+uYYNG2aejdauXTvNnTs327cHAADkTDbDMAxnN5EbxMfHy263Ky4uznLHE5V9+Xtnt4BsdOyt1s5uAQAyTXr/fjv9OkQAAADORiACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACW97cDUXJysq5evZoZvQAAADhFugPRypUrtXDhQoexN998UwULFlSRIkXUvHlzxcbGZnqDAAAAWS3dgeidd95RfHy8+TwiIkKvv/66XnvtNX355Zc6efKk3njjjSxpEgAAICulOxDt27dP9erVM58vW7ZMzZo107hx49SxY0e9++67WrFiRZY0CQAAkJXSHYiuXLmiYsWKmc83bdqkp59+2nz+6KOP6vTp05nbHQAAQDZIdyDy9fVVdHS0JOnq1avavXu3nnzySXP5xYsX5eHhkfkdAgAAZLF0B6Jnn31WYWFhWrhwofr16ycfHx/VrVvXXL5t2zZVrlw5S5oEAADISi7pLRw/frxOnz6tYcOGycfHR4sWLVLevHnN5UuWLFHbtm2zpEkAAICslO5A5OHhkeq0+9v99NNPmdIQAABAduNK1QAAwPLSPUN0+xll97J+/foHbgYAAMAZ0h2Ifv75Z5UpU0atW7eWq6trVvYEAACQrdIdiN566y2Fh4fr3//+t7p3767evXsrICAgK3sDAADIFuk+hmj06NE6cOCAvvnmG125ckVPPvmk6tSpo/fff9/hlh4AAAC5TYYPqg4ODtZHH32kM2fOaPDgwfrkk0/k6+tLKAIAALnWA59ltmPHDm3YsEHR0dEKCAjguCIAAJBrZSgQnT59WlOmTFGlSpX07LPPqmjRotqyZYsiIyOVP3/+DL/5/PnzFRgYqMKFC6tw4cIKDg7WDz/8YC43DEMTJkyQr6+v8ufPr0aNGmn//v0O60hMTNTQoUNVvHhxFShQQO3atdOpU6ccamJjYxUaGiq73S673a7Q0FBdvnw5w/0CAICHU7oDUatWrVShQgVt2bJFb7/9tk6dOqV33nlH1apVe+A3L1WqlN566y1t27ZN27Zt09NPP6327duboWf69OmaMWOG5s6dq6ioKPn4+KhZs2a6cuWKuY6wsDAtX75cS5cu1aZNm3T16lW1adNGKSkpZk23bt20a9curVq1SqtWrdKuXbsUGhr6wH0DAICHi80wDCM9hXny5FHJkiXl5eUlm81217odO3b8rYaKFi2qt99+W71795avr6/CwsI0ZswYSTdng7y9vTVt2jQNGDBAcXFxKlGihBYuXKguXbpIujmL5efnp5UrV6pFixaKjo5WtWrVFBkZqaCgIElSZGSkgoODdfDgwXTffy0+Pl52u11xcXEqXLjw39rG3Kbsy987uwVko2NvtXZ2CwCQadL79ztD9zLLSikpKfr3v/+ta9euKTg4WEePHlVMTIyaN29u1ri7u6thw4aKiIjQgAEDtH37dl2/ft2hxtfXVwEBAYqIiFCLFi20efNm2e12MwxJUt26dWW32xUREXHXQJSYmKjExETzOQeNAwDw8HJ6INq7d6+Cg4P1559/qmDBglq+fLmqVaumiIgISZK3t7dDvbe3t44fPy5JiomJkZubmzw9PVPVxMTEmDVeXl6p3tfLy8usScvUqVM1ceLEv7VtAAAgd/jb9zLbsGGDVq5cqdjY2Ad6feXKlbVr1y5FRkZq4MCB6tGjhw4cOGAuv3P3nGEY99xll1ZNWvX3W8/YsWMVFxdnPk6ePJneTQIAALlMumeI3n77bV29etWcNTEMQyEhIVqzZo2kmzMu69at06OPPpqhBtzc3FSxYkVJUu3atRUVFaX33nvPPG4oJiZGJUuWNOvPnTtnzhr5+PgoKSlJsbGxDrNE586dU7169cyas2fPpnrf8+fPp5p9up27u7vc3d0ztC0AACB3SvcM0ZIlSxzOKFu2bJk2btyoX375RRcuXFDt2rUzZReTYRhKTExUuXLl5OPjo7Vr15rLkpKStGHDBjPs1KpVS66urg41Z86c0b59+8ya4OBgxcXFaevWrWbNli1bFBcXZ9YAAABrS/cM0dGjRxUYGGg+X7lypTp16qQnn3xSkvTqq6/queeey9Cbv/LKKwoJCZGfn5+uXLmipUuX6ueff9aqVatks9kUFhamKVOmyN/fX/7+/poyZYo8PDzUrVs3SZLdblefPn00cuRIFStWTEWLFtWoUaNUvXp1NW3aVJJUtWpVtWzZUv369dMHH3wgSerfv7/atGmT7jPMAADAwy3dgej69esOu5A2b96s4cOHm899fX114cKFDL352bNnFRoaqjNnzshutyswMFCrVq1Ss2bNJN28f1pCQoIGDRqk2NhYBQUFac2aNSpUqJC5jpkzZ8rFxUWdO3dWQkKCmjRpovDwcOXNm9es+fzzzzVs2DDzbLR27dpp7ty5GeoVAAA8vNJ9HaLHHntMYWFh6tmzp06cOKGyZctq37595m60iIgIde7cOdVVoh8WXIcIVsF1iAA8TDL9OkQDBw7UkCFD9Msvv5gXNrz9mKL169erZs2af69rAAAAJ0h3IBowYIBcXFz03Xff6amnnkp1XaLTp0+rd+/emd4gAABAVkv3LjOrY5cZrIJdZgAeJun9+/23L8wIAACQ2xGIAACA5RGIAACA5RGIAACA5T1wIDpy5IhWr16thIQESTdvuQEAAJAbZTgQXbx4UU2bNlWlSpXUqlUrnTlzRpLUt29fjRw5MtMbBAAAyGoZDkQvvfSSXFxcdOLECXl4eJjjXbp00apVqzK1OQAAgOyQ7gsz3rJmzRqtXr1apUqVchj39/fX8ePHM60xAACA7JLhGaJr1645zAzdcuHCBYebvwIAAOQWGQ5ETz31lBYsWGA+t9lsunHjht5++201btw4U5sDAADIDhneZfb222+rUaNG2rZtm5KSkjR69Gjt379fly5d0q+//poVPQIAAGSpDM8QVatWTXv27FGdOnXUrFkzXbt2TR07dtTOnTtVoUKFrOgRAAAgS2V4hkiSfHx8NHHixMzuBQAAwCnSFYj27NmT7hUGBgY+cDMAAADOkK5A9Nhjj8lms8kwDNlsNnP81tWpbx9LSUnJ5BYBAACyVrqOITp69Kh+//13HT16VF999ZXKlSunefPmadeuXdq1a5fmzZunChUq6KuvvsrqfgEAADJdumaIypQpY/77ueee0+zZs9WqVStzLDAwUH5+fnrttdfUoUOHTG8SAAAgK2X4LLO9e/eqXLlyqcbLlSunAwcOZEpTAAAA2SnDgahq1aqaPHmy/vzzT3MsMTFRkydPVtWqVTO1OQAAgOyQ4dPu33//fbVt21Z+fn6qUaOGJGn37t2y2Wz67rvvMr1BAACArJbhQFSnTh0dPXpUixYt0sGDB2UYhrp06aJu3bqpQIECWdEjAABAlnqgCzN6eHiof//+md0LAACAU2T4GCIAAICHDYEIAABYHoEIAABYHoEIAABY3gMFosuXL+vjjz/W2LFjdenSJUnSjh079L///S9TmwMAAMgOGT7LbM+ePWratKnsdruOHTumfv36qWjRolq+fLmOHz+uBQsWZEWfAAAAWSbDM0QjRoxQz549dfjwYeXLl88cDwkJ0caNGzO1OQAAgOyQ4UAUFRWlAQMGpBp/5JFHFBMTkylNAQAAZKcMB6J8+fIpPj4+1fihQ4dUokSJTGkKAAAgO2U4ELVv316TJk3S9evXJUk2m00nTpzQyy+/rE6dOmV6gwAAAFktw4HonXfe0fnz5+Xl5aWEhAQ1bNhQFStWVKFChfTmm29mRY8AAABZKsNnmRUuXFibNm3S+vXrtWPHDt24cUOPP/64mjZtmhX9AQAAZLkMBaLk5GTly5dPu3bt0tNPP62nn346q/oCAADINhnaZebi4qIyZcooJSUlq/oBAADIdhk+hujVV191uEI1AABAbpfhY4hmz56tI0eOyNfXV2XKlFGBAgUclu/YsSPTmgMAAMgOGQ5EHTp0yII2AAAAnCfDgWj8+PFZ0QcAAIDTZDgQ3bJt2zZFR0fLZrOpatWqqlWrVmb2BQAAkG0yHIhOnTqlrl276tdff1WRIkUkSZcvX1a9evW0ZMkS+fn5ZXaPAAAAWSrDZ5n17t1b169fV3R0tC5duqRLly4pOjpahmGoT58+WdEjAABAlsrwDNEvv/yiiIgIVa5c2RyrXLmy5syZoyeffDJTmwMAAMgOGZ4hKl26tHlj19slJyfrkUceyZSmAAAAslOGA9H06dM1dOhQbdu2TYZhSLp5gPXw4cP1zjvvZHqDAAAAWS1du8w8PT1ls9nM59euXVNQUJBcXG6+PDk5WS4uLurduzfXKQIAALlOugLRrFmzsrgNAAAA50lXIOrRo0dW9wEAAOA0D3xhxnPnzuncuXO6ceOGw3hgYODfbgoAACA7ZTgQbd++XT169DCvPXQ7m82mlJSUTGsOAAAgO2Q4EPXq1UuVKlXSv/71L3l7ezscbA0AAJAbZTgQHT16VF9//bUqVqyYFf0AAABkuwxfh6hJkybavXt3VvQCAADgFBmeIfr444/Vo0cP7du3TwEBAXJ1dXVY3q5du0xrDgAAIDtkOBBFRERo06ZN+uGHH1It46BqAACQG2V4l9mwYcMUGhqqM2fO6MaNGw4PwhAAAMiNMhyILl68qJdeekne3t5Z0Q8AAEC2y3Ag6tixo3766aes6AUAAMApMhyIKlWqpLFjx6pnz5569913NXv2bIdHRkydOlVPPPGEChUqJC8vL3Xo0EGHDh1yqDEMQxMmTJCvr6/y58+vRo0aaf/+/Q41iYmJGjp0qIoXL64CBQqoXbt2OnXqlENNbGysQkNDZbfbZbfbFRoaqsuXL2d08wEAwEPIZtx5uen7KFeu3N1XZrPp999/T/e6WrZsqeeff15PPPGEkpOTNW7cOO3du1cHDhxQgQIFJEnTpk3Tm2++qfDwcFWqVEmTJ0/Wxo0bdejQIRUqVEiSNHDgQK1YsULh4eEqVqyYRo4cqUuXLmn79u3KmzevJCkkJESnTp3Shx9+KEnq37+/ypYtqxUrVqSr1/j4eNntdsXFxalw4cLp3saHQdmXv3d2C8hGx95q7ewWACDTpPfvd4YDUVY6f/68vLy8tGHDBj311FMyDEO+vr4KCwvTmDFjJN2cDfL29ta0adM0YMAAxcXFqUSJElq4cKG6dOkiSTp9+rT8/Py0cuVKtWjRQtHR0apWrZoiIyMVFBQkSYqMjFRwcLAOHjyoypUr37c3AhGsgkAE4GGS3r/fGd5ldjvDMFLdz+zviIuLkyQVLVpU0s2rYsfExKh58+Zmjbu7uxo2bKiIiAhJN++tdv36dYcaX19fBQQEmDWbN2+W3W43w5Ak1a1bV3a73ay5U2JiouLj4x0eAADg4fRAgWjBggWqXr268ufPr/z58yswMFALFy78W40YhqERI0aofv36CggIkCTFxMRIUqoz2ry9vc1lMTExcnNzk6en5z1rvLy8Ur2nl5eXWXOnqVOnmscb2e12+fn5/a3tAwAAOVeGA9GMGTM0cOBAtWrVSl9++aW++OILtWzZUv/4xz80c+bMB25kyJAh2rNnj5YsWZJq2Z03kDUM4743lb2zJq36e61n7NixiouLMx8nT55Mz2YAAIBcKMNXqp4zZ47mz5+vF1980Rxr3769Hn30UU2YMEEvvfRShpsYOnSovv32W23cuFGlSpUyx318fCTdnOEpWbKkOX7u3Dlz1sjHx0dJSUmKjY11mCU6d+6c6tWrZ9acPXs21fueP3/+rtdTcnd3l7u7e4a3BQAA5D4ZniE6c+aMGTRuV69ePZ05cyZD6zIMQ0OGDNHXX3+t9evXpzqDrVy5cvLx8dHatWvNsaSkJG3YsMHsoVatWnJ1dXWoOXPmjPbt22fWBAcHKy4uTlu3bjVrtmzZori4uDS3BQAAWEuGA1HFihX15Zdfphr/4osv5O/vn6F1DR48WIsWLdLixYtVqFAhxcTEKCYmRgkJCZJu7uYKCwvTlClTtHz5cu3bt089e/aUh4eHunXrJkmy2+3q06ePRo4cqXXr1mnnzp164YUXVL16dTVt2lSSVLVqVbVs2VL9+vVTZGSkIiMj1a9fP7Vp0yZdZ5gBAICHW4Z3mU2cOFFdunTRxo0b9eSTT8pms2nTpk1at25dmkHpXubPny9JatSokcP4p59+qp49e0qSRo8erYSEBA0aNEixsbEKCgrSmjVrzGsQSdLMmTPl4uKizp07KyEhQU2aNFF4eLh5DSJJ+vzzzzVs2DDzbLR27dpp7ty5Gd18AADwEHqg6xBt375dM2fOVHR0tAzDULVq1TRy5EjVrFkzK3rMEbgOEayC6xABeJik9+93hmeIpJvH7SxatOiBmwMAAMhJ/taFGQEAAB4G6Z4hypMnz32v/WOz2ZScnPy3mwIAAMhO6Q5Ey5cvv+uyiIgIzZkzJ1Nv4wEAAJBd0h2I2rdvn2rs4MGDGjt2rFasWKHu3bvrjTfeyNTmAAAAssMDHUN0+vRp9evXT4GBgUpOTtauXbv02WefqXTp0pndHwAAQJbLUCCKi4vTmDFjVLFiRe3fv1/r1q3TihUrzJuxAgAA5Ebp3mU2ffp0TZs2TT4+PlqyZEmau9AAAAByo3RfmDFPnjzKnz+/mjZt6nAF6Dt9/fXXmdZcTsKFGWEVXJgRwMMk0y/M+OKLL973tHsAAIDcKN2BKDw8PAvbAAAAcB6uVA0AACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACzPqYFo48aNatu2rXx9fWWz2fTNN984LDcMQxMmTJCvr6/y58+vRo0aaf/+/Q41iYmJGjp0qIoXL64CBQqoXbt2OnXqlENNbGysQkNDZbfbZbfbFRoaqsuXL2fx1gEAgNzCqYHo2rVrqlGjhubOnZvm8unTp2vGjBmaO3euoqKi5OPjo2bNmunKlStmTVhYmJYvX66lS5dq06ZNunr1qtq0aaOUlBSzplu3btq1a5dWrVqlVatWadeuXQoNDc3y7QMAALmDzTAMw9lNSJLNZtPy5cvVoUMHSTdnh3x9fRUWFqYxY8ZIujkb5O3trWnTpmnAgAGKi4tTiRIltHDhQnXp0kWSdPr0afn5+WnlypVq0aKFoqOjVa1aNUVGRiooKEiSFBkZqeDgYB08eFCVK1dOV3/x8fGy2+2Ki4tT4cKFM/8DyMHKvvy9s1tANjr2VmtntwAAmSa9f79z7DFER48eVUxMjJo3b26Oubu7q2HDhoqIiJAkbd++XdevX3eo8fX1VUBAgFmzefNm2e12MwxJUt26dWW3280aAABgbS7ObuBuYmJiJEne3t4O497e3jp+/LhZ4+bmJk9Pz1Q1t14fExMjLy+vVOv38vIya9KSmJioxMRE83l8fPyDbQgAAMjxcuwM0S02m83huWEYqcbudGdNWvX3W8/UqVPNg7Dtdrv8/Pwy2DkAAMgtcmwg8vHxkaRUszjnzp0zZ418fHyUlJSk2NjYe9acPXs21frPnz+favbpdmPHjlVcXJz5OHny5N/aHgAAkHPl2EBUrlw5+fj4aO3ateZYUlKSNmzYoHr16kmSatWqJVdXV4eaM2fOaN++fWZNcHCw4uLitHXrVrNmy5YtiouLM2vS4u7ursKFCzs8AADAw8mpxxBdvXpVR44cMZ8fPXpUu3btUtGiRVW6dGmFhYVpypQp8vf3l7+/v6ZMmSIPDw9169ZNkmS329WnTx+NHDlSxYoVU9GiRTVq1ChVr15dTZs2lSRVrVpVLVu2VL9+/fTBBx9Ikvr37682bdqk+wwzAADwcHNqINq2bZsaN25sPh8xYoQkqUePHgoPD9fo0aOVkJCgQYMGKTY2VkFBQVqzZo0KFSpkvmbmzJlycXFR586dlZCQoCZNmig8PFx58+Y1az7//HMNGzbMPButXbt2d732EQAAsJ4ccx2inI7rEMEquA4RgIdJrr8OEQAAQHYhEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMtz6t3uAQDOxc2brYWbN98dM0QAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyLBWI5s2bp3LlyilfvnyqVauWfvnlF2e3BAAAcgDLBKIvvvhCYWFhGjdunHbu3KkGDRooJCREJ06ccHZrAADAySwTiGbMmKE+ffqob9++qlq1qmbNmiU/Pz/Nnz/f2a0BAAAns0QgSkpK0vbt29W8eXOH8ebNmysiIsJJXQEAgJzCxdkNZIcLFy4oJSVF3t7eDuPe3t6KiYlJ8zWJiYlKTEw0n8fFxUmS4uPjs67RHOpG4h/ObgHZyIrf41bGz7e1WPHn+9Y2G4ZxzzpLBKJbbDabw3PDMFKN3TJ16lRNnDgx1bifn1+W9AbkFPZZzu4AQFax8s/3lStXZLfb77rcEoGoePHiyps3b6rZoHPnzqWaNbpl7NixGjFihPn8xo0bunTpkooVK3bXEIWHR3x8vPz8/HTy5EkVLlzY2e0AyET8fFuLYRi6cuWKfH1971lniUDk5uamWrVqae3atXrmmWfM8bVr16p9+/Zpvsbd3V3u7u4OY0WKFMnKNpEDFS5cmF+YwEOKn2/ruNfM0C2WCESSNGLECIWGhqp27doKDg7Whx9+qBMnTugf//iHs1sDAABOZplA1KVLF128eFGTJk3SmTNnFBAQoJUrV6pMmTLObg0AADiZZQKRJA0aNEiDBg1ydhvIBdzd3TV+/PhUu00B5H78fCMtNuN+56EBAAA85CxxYUYAAIB7IRABAADLIxABAADLIxABAADLIxABAADLIxABAADLs9R1iAAA1nPx4kW9/vrr+umnn3Tu3DnduHHDYfmlS5ec1BlyEgIR8BfDMLRs2bK7/tL8+uuvndQZgL/jhRde0G+//aY+ffrI29ubG3QjTQQi4C/Dhw/Xhx9+qMaNG/NLE3iIbNq0SZs2bVKNGjWc3QpyMAIR8JdFixbp66+/VqtWrZzdCoBMVKVKFSUkJDi7DeRwHFQN/MVut6t8+fLObgNAJps3b57GjRunDRs26OLFi4qPj3d4ABKBCDBNmDBBEydO5H+SwEOmSJEiiouL09NPPy0vLy95enrK09NTRYoUkaenp7PbQw7BLjPgL88995yWLFkiLy8vlS1bVq6urg7Ld+zY4aTOAPwd3bt3l5ubmxYvXszxgbgrAhHwl549e2r79u164YUX+KUJPET27dunnTt3qnLlys5uBTkYgQj4y/fff6/Vq1erfv36zm4FQCaqXbu2Tp48SSDCPRGIgL/4+fmpcOHCzm4DQCYbOnSohg8frn/+85+qXr16qt3hgYGBTuoMOYnNMAzD2U0AOcH333+vOXPm6P3331fZsmWd3Q6ATJInT+rzh2w2mwzDkM1mU0pKihO6Qk5DIAL+4unpqT/++EPJycny8PBI9b9ILu8P5E7Hjx+/5/IyZcpkUyfIydhlBvxl1qxZzm4BQBYg8CA9mCECAFjCgQMHdOLECSUlJTmMt2vXzkkdISdhhghIQ0JCgq5fv+4wxgHXQO70+++/65lnntHevXvNY4ckmZfW4BgiSFypGjBdu3ZNQ4YMkZeXlwoWLGhezfbWA0DuNHz4cJUrV05nz56Vh4eH9u/fr40bN6p27dr6+eefnd0ecggCEfCX0aNHa/369Zo3b57c3d318ccfa+LEifL19dWCBQuc3R6AB7R582ZNmjRJJUqUUJ48eZQnTx7Vr19fU6dO1bBhw5zdHnIIAhHwlxUrVmjevHl69tln5eLiogYNGujVV1/VlClT9Pnnnzu7PQAPKCUlRQULFpQkFS9eXKdPn5Z082DrQ4cOObM15CAEIuAvly5dUrly5STdPF7o1mn29evX18aNG53ZGoC/ISAgQHv27JEkBQUFafr06fr11181adIklS9f3sndIacgEAF/KV++vI4dOyZJqlatmr788ktJN2eOihQp4rzGAPwtr776qm7cuCFJmjx5so4fP64GDRpo5cqVmj17tpO7Q07BaffAX2bOnKm8efNq2LBh+umnn9S6dWulpKQoOTlZM2bM0PDhw53dIoBMcunSJXl6enITZ5gIRMBdnDhxQtu2bVOFChVUo0YNZ7cDIBOcPHlSNptNpUqVcnYryGG4DhFwm3Xr1mndunU6d+6cOcV+yyeffOKkrgD8HcnJyZo4caJmz56tq1evSpIKFiyooUOHavz48alu0wNrIhABf5k4caImTZqk2rVrq2TJkkylAw+JIUOGaPny5Zo+fbqCg4Ml3TwVf8KECbpw4YLef/99J3eInIBdZsBfSpYsqenTpys0NNTZrQDIRHa7XUuXLlVISIjD+A8//KDnn39ecXFxTuoMOQlnmQF/SUpKUr169ZzdBoBMli9fPpUtWzbVeNmyZeXm5pb9DSFHIhABf+nbt68WL17s7DYAZLLBgwfrjTfeUGJiojmWmJioN998U0OGDHFiZ8hJ2GUGSxsxYoT57xs3buizzz5TYGCgAgMDUx1oOWPGjOxuD0AmeOaZZ7Ru3Tq5u7ubZ4zu3r1bSUlJatKkiUPt119/7YwWkQNwUDUsbefOnQ7PH3vsMUnSvn37HMY5wBrIvYoUKaJOnTo5jPn5+TmpG+RUzBABAB5qCQkJunHjhgoUKCBJOnbsmL755htVrVpVLVq0cHJ3yCk4hggA8FBr3769Fi5cKEm6fPmy6tatq3fffVcdOnTQ/PnzndwdcgoCEQDgobZjxw41aNBAkrRs2TJ5e3vr+PHjWrBgAfcyg4lABAB4qP3xxx8qVKiQJGnNmjXq2LGj8uTJo7p16+r48eNO7g45BYEIAPBQq1ixor755hudPHlSq1evVvPmzSVJ586dU+HChZ3cHXIKAhEA4KH2+uuva9SoUSpbtqyCgoLM23esWbNGNWvWdHJ3yCk4ywwA8NCLiYnRmTNnVKNGDeXJc3MuYOvWrSpcuLCqVKni5O6QExCIAACA5bHLDAAAWB6BCAAAWB6BCAAAWB6BCMBDyWaz6ZtvvnF2GwByCQIRgFwpJiZGQ4cOVfny5eXu7i4/Pz+1bdtW69atc3ZrAHIh7nYPINc5duyYnnzySRUpUkTTp09XYGCgrl+/rtWrV2vw4ME6ePCgs1sEkMswQwQg1xk0aJBsNpu2bt2qZ599VpUqVdKjjz6qESNGKDIyMs3XjBkzRpUqVZKHh4fKly+v1157TdevXzeX7969W40bN1ahQoVUuHBh1apVS9u2bZMkHT9+XG3btpWnp6cKFCigRx99VCtXrjRfe+DAAbVq1UoFCxaUt7e3QkNDdeHChaz9EABkKgIRgFzl0qVLWrVqlQYPHqwCBQqkWl6kSJE0X1eoUCGFh4frwIEDeu+99/TRRx9p5syZ5vLu3burVKlSioqK0vbt2/Xyyy/L1dVVkjR48GAlJiZq48aN2rt3r6ZNm6aCBQtKks6cOaOGDRvqscce07Zt27Rq1SqdPXtWnTt3zvyNB5Bl2GUGIFc5cuSIDMPI8NWFX331VfPfZcuW1ciRI/XFF19o9OjRkqQTJ07on//8p7lef39/s/7EiRPq1KmTqlevLkkqX768uWz+/Pl6/PHHNWXKFHPsk08+kZ+fn/773/+qUqVKGd9IANmOQAQgV7l1cX2bzZah1y1btkyzZs3SkSNHdPXqVSUnJzvc2HPEiBHq27evFi5cqKZNm+q5555ThQoVJEnDhg3TwIEDtWbNGjVt2lSdOnVSYGCgJGn79u366aefzBmj2/32228EIiCXYJcZgFzF399fNptN0dHR6X5NZGSknn/+eYWEhOi7777Tzp07NW7cOCUlJZk1EyZM0P79+9W6dWutX79e1apV0/LlyyVJffv21e+//67Q0FDt3btXtWvX1pw5cyRJN27cUNu2bbVr1y6Hx+HDh/XUU09l7sYDyDLcywxArhMSEqK9e/fq0KFDqY4junz5sooUKSKbzably5erQ4cOevfddzVv3jz99ttvZl3fvn21bNkyXb58Oc336Nq1q65du6Zvv/021bKxY8fq+++/1549ezRu3Dh99dVX2rdvn1xcmHQHcitmiADkOvPmzVNKSorq1Kmjr776SocPH1Z0dLRmz56t4ODgVPUVK1bUiRMntHTpUv3222+aPXu2OfsjSQkJCRoyZIh+/vlnHT9+XL/++quioqJUtWpVSVJYWJhWr16to0ePaseOHVq/fr25bPDgwbp06ZK6du2qrVu36vfff9eaNWvUu3dvpaSkZM8HAuBvIxAByHXKlSunHTt2qHHjxho5cqQCAgLUrFkzrVu3TvPnz09V3759e7300ksaMmSIHnvsMUVEROi1114zl+fNm1cXL17Uiy++qEqVKqlz584KCQnRxIkTJUkpKSkaPHiwqlatqpYtW6py5cqaN2+eJMnX11e//vqrUlJS1KJFCwUEBGj48OGy2+3Kk4dfsUBuwS4zAABgefz3BQAAWB6BCAAAWB6BCAAAWB6BCAAAWB6BCAAAWB6BCAAAWB6BCAAAWB6BCAAAWB6BCAAAWB6BCAAAWB6BCAAAWB6BCAAAWN7/A/pDFbQh8nLjAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df[\"label\"].value_counts().plot(kind=\"bar\")\n",
    "plt.title(\"Répartition des classes (ham vs spam)\")\n",
    "plt.xlabel(\"Classe\")\n",
    "plt.ylabel(\"Nombre de SMS\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d63bb30",
   "metadata": {},
   "source": [
    "## Préparer NLTK (stopwords + stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "759c3c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\angig\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\angig\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\angig\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Préparer NLTK (stopwords + stemmer): \n",
    "'''permettre le pré-traitement du texte en supprimant les mots vides et en réduisant les mots à leur racine.'''\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stemmer = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89ec94d",
   "metadata": {},
   "source": [
    "## Tokenisation, suppression des stopwords et Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c7faa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage des données\n",
    "'''cette fonction nettoie le texte en supprimant les URLs, les chiffres, la ponctuation, les stopwords et en appliquant le stemming.'''\n",
    "def clean_text(text):\n",
    "    # Convertir en minuscules\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Enlever les URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \" \", text)\n",
    "    \n",
    "    # Enlever les chiffres\n",
    "    text = re.sub(r\"\\d+\", \" \", text)\n",
    "    \n",
    "    # Enlever la ponctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    \n",
    "    # Découper en mots\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Enlever les stopwords + stemming\n",
    "    tokens = [\n",
    "        stemmer.stem(w) for w in tokens\n",
    "        if w not in stop_words\n",
    "    ]\n",
    "    \n",
    "    # Recombiner en une chaîne\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cea532b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entri wkli comp win fa cup final tkt st m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say earli hor u c alreadi say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah dont think goe usf live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  go jurong point crazi avail bugi n great world...  \n",
       "1                              ok lar joke wif u oni  \n",
       "2  free entri wkli comp win fa cup final tkt st m...  \n",
       "3                u dun say earli hor u c alreadi say  \n",
       "4          nah dont think goe usf live around though  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# application de la fonction de nettoyage\n",
    "df[\"cleaned_text\"] = df[\"text\"].apply(clean_text)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e664731e",
   "metadata": {},
   "source": [
    "## TF-IDF (Term Frequency-Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c71b05af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5572, 5000), (4457, 5000), (1115, 5000))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorisation TF-IDF et découpage train/test\n",
    "'''On crée une représentation numérique des SMS (5000 vecteurs TF-IDF), puis on sépare les données en train/test (80/20). '''\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Transformer les textes nettoyés en vecteurs TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df[\"cleaned_text\"])\n",
    "\n",
    "# Encoder la cible (ham=0, spam=1)\n",
    "y = df[\"label\"].map({\"ham\": 0, \"spam\": 1}).values\n",
    "\n",
    "# Découpage train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X.shape, X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6641d891",
   "metadata": {},
   "source": [
    "5572 SMS au total, chacun représenté par 5000 valeurs TF-IDF\n",
    "\n",
    "4457 SMS pour l’apprentissage (train)\n",
    "\n",
    "1115 SMS pour le test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc9fb2d",
   "metadata": {},
   "source": [
    "## Réduction de la dimensionnalité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "737b75d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4457, 5000), (1115, 5000))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convertir les matrices en format compatible Keras\n",
    "'''On convertit X_train et X_test en versions denses (X_train_dense, X_test_dense) pour les donner à l’autoencoder.'''\n",
    "# Conversion des matrices TF-IDF sparse en tableaux denses (float32)\n",
    "X_train_dense = X_train.toarray().astype(\"float32\")\n",
    "X_test_dense  = X_test.toarray().astype(\"float32\")\n",
    "\n",
    "X_train_dense.shape, X_test_dense.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e4b9bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d00384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"autoencoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ latent_space (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,565,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m2,560,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ latent_space (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m66,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m)           │     \u001b[38;5;34m2,565,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,257,224</span> (20.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,257,224\u001b[0m (20.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,257,224</span> (20.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,257,224\u001b[0m (20.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Définir l’architecture de l’autoencoder\n",
    "'''L’autoencoder doit reconstruire les vecteurs TF-IDF d’origine, qui sont des valeurs continues non bornées. \n",
    "Une activation linéaire est donc utilisée en sortie pour permettre au réseau de produire librement n’importe quelle valeur réelle.\n",
    "Une activation sigmoïde limiterait la sortie à l’intervalle [0, 1], empêchant une reconstruction fidèle.\n",
    "L’usage de la MSE comme fonction de perte confirme que la sortie est un problème de régression et non de classification.'''\n",
    "# Dimension d'entrée : nombre de features TF-IDF (5000)\n",
    "input_dim = X_train_dense.shape[1]\n",
    "encoding_dim = 128  # taille de l'espace latent (compressé)\n",
    "\n",
    "# Couche d'entrée\n",
    "input_layer = keras.Input(shape=(input_dim,)).\n",
    "\n",
    "# Encodeur : 1ère couche cachée + couche latente\n",
    "encoded = layers.Dense(512, activation=\"relu\")(input_layer)\n",
    "latent = layers.Dense(encoding_dim, activation=\"relu\", name=\"latent_space\")(encoded)\n",
    "\n",
    "# Décodeur : on reconstruit vers la dimension d'origine\n",
    "decoded = layers.Dense(512, activation=\"relu\")(latent)\n",
    "output_layer = layers.Dense(input_dim, activation=\"linear\")(decoded)\n",
    "\n",
    "# Modèle autoencoder complet (entrée -> reconstruction)\n",
    "autoencoder = keras.Model(inputs=input_layer, outputs=output_layer, name=\"autoencoder\")\n",
    "\n",
    "# Modèle encodeur seul (entrée -> espace latent)\n",
    "encoder = keras.Model(inputs=input_layer, outputs=latent, name=\"encoder\")\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "40f160c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - loss: 1.9879e-04 - val_loss: 1.9778e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 1.9824e-04 - val_loss: 1.9782e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - loss: 1.9827e-04 - val_loss: 1.9786e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 1.9827e-04 - val_loss: 1.9782e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 1.9829e-04 - val_loss: 1.9785e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - loss: 1.9827e-04 - val_loss: 1.9783e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 1.9821e-04 - val_loss: 1.9779e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 1.9811e-04 - val_loss: 1.9762e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 1.9788e-04 - val_loss: 1.9733e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - loss: 1.9745e-04 - val_loss: 1.9686e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 1.9686e-04 - val_loss: 1.9636e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 1.9639e-04 - val_loss: 1.9604e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 1.9617e-04 - val_loss: 1.9591e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - loss: 1.9601e-04 - val_loss: 1.9569e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 1.9580e-04 - val_loss: 1.9546e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 1.9543e-04 - val_loss: 1.9505e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - loss: 1.9486e-04 - val_loss: 1.9430e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - loss: 1.9407e-04 - val_loss: 1.9344e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 1.9326e-04 - val_loss: 1.9277e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 1.9256e-04 - val_loss: 1.9222e-04\n"
     ]
    }
   ],
   "source": [
    "'''optimiseur : adam pour l’apprentissage\n",
    "fonction de perte : mse (erreur quadratique moyenne) → pour mesurer la différence entre l’entrée et la reconstruction.'''\n",
    "autoencoder.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mse\"\n",
    ")\n",
    "#Entraîner l’autoencoder\n",
    "history = autoencoder.fit(\n",
    "    X_train_dense, X_train_dense,  # entrée = cible\n",
    "    epochs=20,                    \n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ea440d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((4457, 128), (1115, 128))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extraire les nouvelles représentations\n",
    "'''Une fois l’autoencoder entraîné, on utilise encoder pour obtenir les nouvelles features compressées'''\n",
    "X_train_encoded = encoder.predict(X_train_dense)\n",
    "X_test_encoded  = encoder.predict(X_test_dense)\n",
    "\n",
    "X_train_encoded.shape, X_test_encoded.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2e0c7f",
   "metadata": {},
   "source": [
    "4457 SMS d’entraînement, chacun résumé par 128 nombres (au lieu de 5000)\n",
    "\n",
    "1115 SMS de test, aussi résumés par 128 nombres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba92225d",
   "metadata": {},
   "source": [
    "## 3. Classification avec les vecteurs compressés (128 dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6400ef5",
   "metadata": {},
   "source": [
    "### 3.1 régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd7b2017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importer les outils de classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "195681f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Créer et entraîner le modèle sur l’espace latent\n",
    "# Créer le modèle de régression logistique\n",
    "log_reg_latent = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Entraîner sur les vecteurs compressés (128 dims)\n",
    "log_reg_latent.fit(X_train_encoded, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f7b3735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédire les classes sur le test (dans l'espace latent)\n",
    "y_pred_latent = log_reg_latent.predict(X_test_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b014a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (avec autoencoder) : 0.8932735426008969\n",
      "\n",
      "Classification report (avec autoencoder) :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.89      0.99      0.94       966\n",
      "        spam       0.86      0.24      0.38       149\n",
      "\n",
      "    accuracy                           0.89      1115\n",
      "   macro avg       0.88      0.62      0.66      1115\n",
      "weighted avg       0.89      0.89      0.87      1115\n",
      "\n",
      "Matrice de confusion (avec autoencoder) :\n",
      "[[960   6]\n",
      " [113  36]]\n"
     ]
    }
   ],
   "source": [
    "#evaluer les performances\n",
    "# Accuracy globale\n",
    "acc_latent = accuracy_score(y_test, y_pred_latent)\n",
    "print(\"Accuracy (avec autoencoder) :\", acc_latent)\n",
    "\n",
    "# Rapport détaillé\n",
    "print(\"\\nClassification report (avec autoencoder) :\")\n",
    "print(classification_report(y_test, y_pred_latent, target_names=[\"ham\", \"spam\"]))\n",
    "\n",
    "# Matrice de confusion\n",
    "print(\"Matrice de confusion (avec autoencoder) :\")\n",
    "print(confusion_matrix(y_test, y_pred_latent))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a4313e",
   "metadata": {},
   "source": [
    "Avec les représentations latentes produites par l’autoencoder (128 dimensions), l’accuracy globale atteint 90%. Cependant, la performance sur la classe spam reste très faible, avec un rappel de 30% seulement.\n",
    "Cela signifie que le modèle ne détecte que 30% des messages réellement indésirables.\n",
    "L’analyse de la matrice de confusion confirme que 105 spams sont incorrectement classés comme ham.\n",
    "Cette perte de performance s’explique par la réduction de dimension : en compressant les vecteurs TF-IDF (5000 dimensions) vers un espace latent de seulement 128 dimensions, l’autoencoder supprime des informations importantes pour la détection des spams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7536778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner un modèle SANS autoencoder (TF-IDF brut)\n",
    "# Modèle baseline (sans autoencoder)\n",
    "log_reg_tfidf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Entraînement sur les vecteurs TF-IDF bruts\n",
    "log_reg_tfidf.fit(X_train, y_train)\n",
    "y_pred_tfidf = log_reg_tfidf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9acdbcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (sans autoencoder) : 0.9641255605381166\n",
      "\n",
      "Classification report (sans autoencoder) :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98       966\n",
      "        spam       1.00      0.73      0.84       149\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.98      0.87      0.91      1115\n",
      "weighted avg       0.97      0.96      0.96      1115\n",
      "\n",
      "Matrice de confusion (sans autoencoder) :\n",
      "[[966   0]\n",
      " [ 40 109]]\n"
     ]
    }
   ],
   "source": [
    "#Evaluer les performances du modèle baseline\n",
    "# Accuracy globale\n",
    "acc_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
    "print(\"Accuracy (sans autoencoder) :\", acc_tfidf)\n",
    "\n",
    "# Rapport précision / rappel / F1\n",
    "print(\"\\nClassification report (sans autoencoder) :\")\n",
    "print(classification_report(y_test, y_pred_tfidf, target_names=[\"ham\", \"spam\"]))\n",
    "\n",
    "# Matrice de confusion\n",
    "print(\"Matrice de confusion (sans autoencoder) :\")\n",
    "print(confusion_matrix(y_test, y_pred_tfidf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd26de25",
   "metadata": {},
   "source": [
    "L’autoencoder réduit la dimension de 5000 à 128, ce qui simplifie le problème mais entraîne une perte d’information importante, surtout pour les spams qui sont rares et contiennent des mots très spécifiques.\n",
    "Le modèle TF-IDF sans réduction de dimension conserve mieux ces signaux et obtient donc de meilleures performances, notamment un rappel spam beaucoup plus élevé (73% vs 30%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c316625",
   "metadata": {},
   "source": [
    "### 3.2 SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0e817fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SVM (avec données réduites) ===\n",
      "Accuracy : 0.9165919282511211\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.92      0.99      0.95       966\n",
      "        spam       0.91      0.42      0.57       149\n",
      "\n",
      "    accuracy                           0.92      1115\n",
      "   macro avg       0.91      0.70      0.76      1115\n",
      "weighted avg       0.92      0.92      0.90      1115\n",
      "\n",
      "Matrice de confusion :\n",
      "[[960   6]\n",
      " [ 87  62]]\n"
     ]
    }
   ],
   "source": [
    "# SVM sur l’espace latent (128 dims)\n",
    "from sklearn.svm import LinearSVC\n",
    "#LinearSVC est la version optimisée du SVM pour les très grandes dimensions (comme TF-IDF = 5000 features)\n",
    "#Entraîner un SVM linéaire sur les données TF-IDF brutes\n",
    "svm_latent = LinearSVC()\n",
    "svm_latent.fit(X_train_encoded, y_train)\n",
    "\n",
    "y_pred_svm_latent = svm_latent.predict(X_test_encoded)\n",
    "\n",
    "print(\"\\n=== SVM (avec données réduites) ===\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred_svm_latent))\n",
    "print(classification_report(y_test, y_pred_svm_latent, target_names=[\"ham\", \"spam\"]))\n",
    "print(\"Matrice de confusion :\")\n",
    "print(confusion_matrix(y_test, y_pred_svm_latent))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84c0d5b",
   "metadata": {},
   "source": [
    "Le SVM appliqué sur les représentations réduites par autoencoder obtient une accuracy de 93% et détecte 51% des spams. Bien que ce résultat soit supérieur à celui obtenu par la régression logistique dans le même espace latent (30% de rappel)\n",
    "Cela confirme que la réduction de dimensionnalité par autoencoder supprime des informations importantes, en particulier celles spécifiques aux messages indésirables, ce qui limite la capacité des modèles à identifier les spams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2730a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svm_model = LinearSVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire sur le test\n",
    "y_pred_svm = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a402d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM : 0.9856502242152466\n",
      "\n",
      "Classification report (SVM) :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       966\n",
      "        spam       0.99      0.90      0.94       149\n",
      "\n",
      "    accuracy                           0.99      1115\n",
      "   macro avg       0.99      0.95      0.97      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      "\n",
      "Matrice de confusion (SVM) :\n",
      "[[965   1]\n",
      " [ 15 134]]\n"
     ]
    }
   ],
   "source": [
    "#Evaluer les performances du modèle baseline\n",
    "print(\"Accuracy SVM :\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"\\nClassification report (SVM) :\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=[\"ham\", \"spam\"]))\n",
    "print(\"Matrice de confusion (SVM) :\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3314bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_svm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"ham\", \"spam\"])\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Matrice de confusion - SVM TF-IDF\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b041d779",
   "metadata": {},
   "source": [
    "Le SVM entraîné sur les vecteurs TF-IDF bruts est le modèle le plus performant.\n",
    "Il obtient une accuracy de 98.6 %, une précision spam de 0.99 et un rappel spam de 0.90, ce qui montre qu’il détecte efficacement les messages indésirables tout en produisant très peu de faux positifs.\n",
    "Cette performance élevée s’explique par la capacité du SVM à exploiter efficacement les données en haute dimension (5000 features TF-IDF), sans perte d’information liée à une réduction de dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2096747e",
   "metadata": {},
   "source": [
    "### 3.3 MLP (réseau de neurones) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eaf2f7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MLP (avec données réduites) ===\n",
      "Accuracy : 0.9363228699551569\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      0.96      0.96       966\n",
      "        spam       0.77      0.75      0.76       149\n",
      "\n",
      "    accuracy                           0.94      1115\n",
      "   macro avg       0.86      0.86      0.86      1115\n",
      "weighted avg       0.94      0.94      0.94      1115\n",
      "\n",
      "Matrice de confusion :\n",
      "[[932  34]\n",
      " [ 37 112]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\angig\\anaconda3\\envs\\IA_TraitementDonnees\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#MLP (réseau de neurones) sur l’espace latent (128 dims)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_latent = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),  # 2 couches cachées : 64 puis 32 neurones\n",
    "    activation=\"relu\",\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "mlp_latent.fit(X_train_encoded, y_train)\n",
    "\n",
    "y_pred_mlp_latent = mlp_latent.predict(X_test_encoded)\n",
    "\n",
    "print(\"\\n=== MLP (avec données réduites) ===\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred_mlp_latent))\n",
    "print(classification_report(y_test, y_pred_mlp_latent, target_names=[\"ham\", \"spam\"]))\n",
    "print(\"Matrice de confusion :\")\n",
    "print(confusion_matrix(y_test, y_pred_mlp_latent))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de18348",
   "metadata": {},
   "source": [
    "Parmi les modèles entraînés sur les données réduites, le MLP offre les meilleures performances globales, notamment pour la classe spam. Toutefois, l’ensemble des modèles latents montre une perte d’efficacité par rapport aux modèles entraînés directement sur les vecteurs TF-IDF, confirmant que la réduction de dimension supprime des informations importantes pour la détection du spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4b54401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MLP (TF-IDF brut) ===\n",
      "Accuracy : 0.9838565022421525\n",
      "\n",
      "Classification report (MLP TF-IDF) :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       966\n",
      "        spam       0.98      0.90      0.94       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.95      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Matrice de confusion (MLP TF-IDF) :\n",
      "[[963   3]\n",
      " [ 15 134]]\n"
     ]
    }
   ],
   "source": [
    "#MLP (réseau de neurones) sur données TF-IDF brutes\n",
    "mlp_tfidf = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64),  # 2 couches cachées\n",
    "    activation='relu',\n",
    "    max_iter=300,                  \n",
    "    random_state=42\n",
    ")\n",
    "mlp_tfidf.fit(X_train, y_train)\n",
    "\n",
    "#predire sur le test\n",
    "y_pred_mlp_tfidf = mlp_tfidf.predict(X_test)\n",
    "\n",
    "#evaluate les performances\n",
    "print(\"=== MLP (TF-IDF brut) ===\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred_mlp_tfidf))\n",
    "\n",
    "print(\"\\nClassification report (MLP TF-IDF) :\")\n",
    "print(classification_report(y_test, y_pred_mlp_tfidf, target_names=[\"ham\", \"spam\"]))\n",
    "\n",
    "print(\"Matrice de confusion (MLP TF-IDF) :\")\n",
    "print(confusion_matrix(y_test, y_pred_mlp_tfidf))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03991cb2",
   "metadata": {},
   "source": [
    "Le MLP entraîné sur les TF-IDF bruts offre une excellente performance, avec une accuracy de 98.4 % et une forte capacité à détecter les messages indésirables (rappel de 90 %).\n",
    "Sa sensibilité élevée aux spams et son faible taux de fausses alertes en font un modèle très robuste pour la classification SMS dans un contexte réel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e940ec88",
   "metadata": {},
   "source": [
    "### 3.4 Comparaison des modeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "716e1a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "#  MODÈLES SUR DONNÉES BRUTES (TF-IDF)  #\n",
      "##################################################\n",
      "\n",
      "========== Logistic Regression (TF-IDF brut) ==========\n",
      "Accuracy : 0.96\n",
      "\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98       966\n",
      "        spam       1.00      0.73      0.84       149\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.98      0.87      0.91      1115\n",
      "weighted avg       0.97      0.96      0.96      1115\n",
      "\n",
      "Matrice de confusion :\n",
      "[[966   0]\n",
      " [ 40 109]]\n",
      "\n",
      "========== SVM linéaire (TF-IDF brut) ==========\n",
      "Accuracy : 0.99\n",
      "\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       966\n",
      "        spam       0.99      0.90      0.94       149\n",
      "\n",
      "    accuracy                           0.99      1115\n",
      "   macro avg       0.99      0.95      0.97      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      "\n",
      "Matrice de confusion :\n",
      "[[965   1]\n",
      " [ 15 134]]\n",
      "\n",
      "========== MLP (TF-IDF brut) ==========\n",
      "Accuracy : 0.98\n",
      "\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       966\n",
      "        spam       0.98      0.90      0.94       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.95      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Matrice de confusion :\n",
      "[[963   3]\n",
      " [ 15 134]]\n",
      "\n",
      "##################################################\n",
      "#  MODÈLES SUR DONNÉES RÉDUITES (LATENT)  #\n",
      "##################################################\n",
      "\n",
      "========== Logistic Regression (Latent 128 dims) ==========\n",
      "Accuracy : 0.89\n",
      "\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.89      0.99      0.94       966\n",
      "        spam       0.86      0.24      0.38       149\n",
      "\n",
      "    accuracy                           0.89      1115\n",
      "   macro avg       0.88      0.62      0.66      1115\n",
      "weighted avg       0.89      0.89      0.87      1115\n",
      "\n",
      "Matrice de confusion :\n",
      "[[960   6]\n",
      " [113  36]]\n",
      "\n",
      "========== SVM linéaire (Latent 128 dims) ==========\n",
      "Accuracy : 0.92\n",
      "\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.92      0.99      0.95       966\n",
      "        spam       0.91      0.42      0.57       149\n",
      "\n",
      "    accuracy                           0.92      1115\n",
      "   macro avg       0.91      0.70      0.76      1115\n",
      "weighted avg       0.92      0.92      0.90      1115\n",
      "\n",
      "Matrice de confusion :\n",
      "[[960   6]\n",
      " [ 87  62]]\n",
      "\n",
      "========== MLP (Latent 128 dims) ==========\n",
      "Accuracy : 0.94\n",
      "\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      0.96      0.96       966\n",
      "        spam       0.77      0.75      0.76       149\n",
      "\n",
      "    accuracy                           0.94      1115\n",
      "   macro avg       0.86      0.86      0.86      1115\n",
      "weighted avg       0.94      0.94      0.94      1115\n",
      "\n",
      "Matrice de confusion :\n",
      "[[932  34]\n",
      " [ 37 112]]\n",
      "\n",
      "\n",
      "===== TABLEAU COMPARATIF GLOBAL =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\angig\\anaconda3\\envs\\IA_TraitementDonnees\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Espace</th>\n",
       "      <th>Modèle</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall_spam</th>\n",
       "      <th>F1_spam</th>\n",
       "      <th>Precision_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Latent 128 dims</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Latent 128 dims</td>\n",
       "      <td>SVM linéaire</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Latent 128 dims</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TF-IDF brut</td>\n",
       "      <td>SVM linéaire</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TF-IDF brut</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF-IDF brut</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Espace               Modèle  Accuracy  Recall_spam  F1_spam  \\\n",
       "5  Latent 128 dims                  MLP      0.94         0.75     0.76   \n",
       "4  Latent 128 dims         SVM linéaire      0.92         0.42     0.57   \n",
       "3  Latent 128 dims  Logistic Regression      0.89         0.24     0.38   \n",
       "1      TF-IDF brut         SVM linéaire      0.99         0.90     0.94   \n",
       "2      TF-IDF brut                  MLP      0.98         0.90     0.94   \n",
       "0      TF-IDF brut  Logistic Regression      0.96         0.73     0.84   \n",
       "\n",
       "   Precision_spam  \n",
       "5            0.77  \n",
       "4            0.91  \n",
       "3            0.86  \n",
       "1            0.99  \n",
       "2            0.98  \n",
       "0            1.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test, results_list, space_label):\n",
    "    \"\"\"\n",
    "    Entraîne un modèle, affiche les résultats avec 2 décimales\n",
    "    et sauvegarde accuracy + recall + F1 + precision pour la classe 'spam'.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*10} {name} ({space_label}) {'='*10}\")\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy : {acc:.2f}\\n\")   # <<< 2 décimales\n",
    "\n",
    "    # Rapport complet\n",
    "    report = classification_report(\n",
    "        y_test, y_pred,\n",
    "        target_names=[\"ham\", \"spam\"],\n",
    "        digits=2  # <<< 2 décimales dans le rapport\n",
    "    )\n",
    "    print(\"Classification report :\")\n",
    "    print(report)\n",
    "\n",
    "    # Matrice de confusion\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Matrice de confusion :\")\n",
    "    print(cm)\n",
    "\n",
    "    # Extraire précision / rappel / F1 pour la classe spam\n",
    "    report_dict = classification_report(\n",
    "        y_test, y_pred,\n",
    "        target_names=[\"ham\", \"spam\"],\n",
    "        output_dict=True\n",
    "    )\n",
    "    \n",
    "    spam_precision = round(report_dict[\"spam\"][\"precision\"], 2)\n",
    "    spam_recall = round(report_dict[\"spam\"][\"recall\"], 2)\n",
    "    spam_f1 = round(report_dict[\"spam\"][\"f1-score\"], 2)\n",
    "    acc_rounded = round(acc, 2)\n",
    "\n",
    "    # Sauver dans la liste des résultats\n",
    "    results_list.append({\n",
    "        \"Espace\": space_label,\n",
    "        \"Modèle\": name,\n",
    "        \"Accuracy\": acc_rounded,\n",
    "        \"Recall_spam\": spam_recall,\n",
    "        \"F1_spam\": spam_f1,\n",
    "        \"Precision_spam\": spam_precision\n",
    "    })\n",
    "\n",
    "\n",
    "# Liste pour stocker tous les résultats\n",
    "results = []\n",
    "\n",
    "# ─────────────────────────────\n",
    "# 1) MODÈLES SUR TF-IDF BRUT\n",
    "# ─────────────────────────────\n",
    "print(\"#\" * 50)\n",
    "print(\"#  MODÈLES SUR DONNÉES BRUTES (TF-IDF)  #\")\n",
    "print(\"#\" * 50)\n",
    "\n",
    "logreg_tfidf = LogisticRegression(max_iter=1000)\n",
    "evaluate_model(\"Logistic Regression\", logreg_tfidf,\n",
    "               X_train, y_train, X_test, y_test,\n",
    "               results, \"TF-IDF brut\")\n",
    "\n",
    "svm_tfidf = LinearSVC()\n",
    "evaluate_model(\"SVM linéaire\", svm_tfidf,\n",
    "               X_train, y_train, X_test, y_test,\n",
    "               results, \"TF-IDF brut\")\n",
    "\n",
    "mlp_tfidf = MLPClassifier(hidden_layer_sizes=(128, 64),\n",
    "                          activation=\"relu\",\n",
    "                          max_iter=300,\n",
    "                          random_state=42)\n",
    "evaluate_model(\"MLP\", mlp_tfidf,\n",
    "               X_train, y_train, X_test, y_test,\n",
    "               results, \"TF-IDF brut\")\n",
    "\n",
    "# ─────────────────────────────\n",
    "# 2) MODÈLES SUR DONNÉES RÉDUITES (LATENT 128)\n",
    "# ─────────────────────────────\n",
    "print(\"\\n\" + \"#\" * 50)\n",
    "print(\"#  MODÈLES SUR DONNÉES RÉDUITES (LATENT)  #\")\n",
    "print(\"#\" * 50)\n",
    "\n",
    "logreg_latent = LogisticRegression(max_iter=1000)\n",
    "evaluate_model(\"Logistic Regression\", logreg_latent,\n",
    "               X_train_encoded, y_train, X_test_encoded, y_test,\n",
    "               results, \"Latent 128 dims\")\n",
    "\n",
    "svm_latent = LinearSVC()\n",
    "evaluate_model(\"SVM linéaire\", svm_latent,\n",
    "               X_train_encoded, y_train, X_test_encoded, y_test,\n",
    "               results, \"Latent 128 dims\")\n",
    "\n",
    "mlp_latent = MLPClassifier(hidden_layer_sizes=(64, 32),\n",
    "                           activation=\"relu\",\n",
    "                           max_iter=300,\n",
    "                           random_state=42)\n",
    "evaluate_model(\"MLP\", mlp_latent,\n",
    "               X_train_encoded, y_train, X_test_encoded, y_test,\n",
    "               results, \"Latent 128 dims\")\n",
    "\n",
    "# ─────────────────────────────\n",
    "# 3) TABLEAU COMPARATIF FINAL\n",
    "# ─────────────────────────────\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results.sort_values(by=[\"Espace\", \"Accuracy\"], ascending=[True, False])\n",
    "\n",
    "print(\"\\n\\n===== TABLEAU COMPARATIF GLOBAL =====\")\n",
    "display(df_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29fe578",
   "metadata": {},
   "source": [
    "Les modèles entraînés sur les vecteurs TF-IDF bruts surpassent largement ceux entraînés sur l’espace latent réduit, avec une accurary proche de 99 % et un rappel spam de 90 %. Le SVM linéaire constitue le meilleur modèle du projet. Dans l’espace latent (128 dimensions), seul le MLP obtient des performances acceptables, avec un rappel spam de 70 %, confirmant que la réduction de dimension par autoencoder entraîne une perte d’information significative pour la classification du spam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dd5a75",
   "metadata": {},
   "source": [
    "## 5. Pistes d'amelioration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25532bbb",
   "metadata": {},
   "source": [
    "Plusieurs améliorations peuvent être envisagées pour renforcer la performance et la robustesse du modèle :\n",
    "\n",
    "- Représentation textuelle avancée\n",
    "Utiliser des embeddings préentraînés (Word2Vec, FastText, BERT) permettrait de capturer la sémantique des mots, en allant au-delà des simples fréquences TF-IDF.\n",
    "\n",
    "- Optimisation de l’autoencoder\n",
    "Tester des architectures plus profondes, augmenter le nombre d’époques ou utiliser un denoising autoencoder pourrait réduire la perte d’information observée lors de la compression.\n",
    "\n",
    "- Rééquilibrage des classes\n",
    "Appliquer SMOTE ou des poids de classes (class weights) pourrait améliorer le rappel de la classe spam, particulièrement sensible aux données rares.\n",
    "\n",
    "- Recherche d’hyperparamètres\n",
    "Utiliser GridSearchCV, RandomizedSearchCV ou une optimisation bayésienne (Optuna) permettrait d’ajuster automatiquement les paramètres des modèles supervisés pour de meilleures performances.\n",
    "\n",
    "- Extraction textuelle enrichie\n",
    "Intégrer des n-grams (bigrams, trigrams) et une lemmatisation plus avancée pourrait renforcer la détection de motifs typiques du spam.\n",
    "\n",
    "- Évaluation plus robuste\n",
    "Mettre en place une validation croisée (cross-validation) réduirait la variance des résultats et fournirait une estimation plus fiable des performances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69ea67c",
   "metadata": {},
   "source": [
    "# Exploration des pistes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1036ac",
   "metadata": {},
   "source": [
    "## Extraction textuelle enrichie (n-grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1775a2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X_ngrams : (5572, 5000)\n",
      "Train : (4457, 5000)  Test : (1115, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Extraction textuelle enrichie (n-grams)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TF-IDF avec unigrams + bigrams\n",
    "vectorizer_ngrams = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2)   # mots seuls + paires de mots\n",
    ")\n",
    "\n",
    "X_ngrams = vectorizer_ngrams.fit_transform(df[\"cleaned_text\"])\n",
    "y = df[\"label\"].map({\"ham\": 0, \"spam\": 1}).values\n",
    "\n",
    "print(\"Shape X_ngrams :\", X_ngrams.shape)\n",
    "\n",
    "X_train_ng, X_test_ng, y_train_ng, y_test_ng = train_test_split(\n",
    "    X_ngrams, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "print(\"Train :\", X_train_ng.shape, \" Test :\", X_test_ng.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e06bee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== SVM (TF-IDF n-grams) (TF-IDF n-grams) ==========\n",
      "Accuracy : 0.98\n",
      "\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99       966\n",
      "        spam       0.98      0.91      0.94       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.95      0.97      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Matrice de confusion :\n",
      "[[963   3]\n",
      " [ 14 135]]\n",
      "\n",
      "========== MLP (TF-IDF n-grams) (TF-IDF n-grams) ==========\n",
      "Accuracy : 0.98\n",
      "\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       966\n",
      "        spam       0.97      0.89      0.93       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.94      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Matrice de confusion :\n",
      "[[962   4]\n",
      " [ 16 133]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# SVM sur TF-IDF + n-grams\n",
    "svm_ngrams = LinearSVC()\n",
    "evaluate_model(\"SVM (TF-IDF n-grams)\", svm_ngrams,\n",
    "               X_train_ng, y_train_ng, X_test_ng, y_test_ng,\n",
    "               results, \"TF-IDF n-grams\")\n",
    "\n",
    "# MLP sur TF-IDF + n-grams\n",
    "mlp_ngrams = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64),\n",
    "    activation=\"relu\",\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "evaluate_model(\"MLP (TF-IDF n-grams)\", mlp_ngrams,\n",
    "               X_train_ng, y_train_ng, X_test_ng, y_test_ng,\n",
    "               results, \"TF-IDF n-grams\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcfb45e",
   "metadata": {},
   "source": [
    "L’ajout de bigrams dans la vectorisation TF-IDF permet d’améliorer légèrement les performances du SVM, notamment sur la détection des spams (recall de 0.91 contre 0.90 sans n-grams). Le MLP obtient des performances comparables à celles obtenues avec le TF-IDF classique, indiquant que ce type de modèle exploite déjà efficacement les interactions entre mots. Ainsi, l’enrichissement par n-grams est surtout bénéfique pour les modèles linéaires."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc683dd",
   "metadata": {},
   "source": [
    "## Rééquilibrage des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41671949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== LogReg (balanced, TF-IDF) (TF-IDF brut) ==========\n",
      "Accuracy : 0.98\n",
      "\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       966\n",
      "        spam       0.92      0.92      0.92       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.95      0.95      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Matrice de confusion :\n",
      "[[954  12]\n",
      " [ 12 137]]\n",
      "\n",
      "========== SVM (balanced, TF-IDF) (TF-IDF brut) ==========\n",
      "Accuracy : 0.98\n",
      "\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       966\n",
      "        spam       0.95      0.92      0.94       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.96      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Matrice de confusion :\n",
      "[[959   7]\n",
      " [ 12 137]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# LogReg pondérée\n",
    "logreg_bal = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "evaluate_model(\"LogReg (balanced, TF-IDF)\", logreg_bal,\n",
    "               X_train, y_train, X_test, y_test,\n",
    "               results, \"TF-IDF brut\")\n",
    "\n",
    "# SVM pondéré\n",
    "svm_bal = LinearSVC(class_weight=\"balanced\")\n",
    "evaluate_model(\"SVM (balanced, TF-IDF)\", svm_bal,\n",
    "               X_train, y_train, X_test, y_test,\n",
    "               results, \"TF-IDF brut\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49647f7a",
   "metadata": {},
   "source": [
    "L’utilisation de class_weight=\"balanced\" a permis d’augmenter significativement la sensibilité des modèles à la classe minoritaire (spam). La régression logistique, initialement limitée à 73 % de rappel spam, atteint désormais 92 %, ce qui représente un gain majeur. Le SVM linéaire bénéficie également de l’ajustement, passant de 90 % à 92 % de rappel spam. Ce renforcement de la détection s’accompagne d’une légère augmentation des faux positifs, mais améliore globalement le compromis précision/rappel. L’équilibrage des classes constitue donc une amélioration simple et très efficace pour ce type de problème textuel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4711c7be",
   "metadata": {},
   "source": [
    "## embeddings (BERT-like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c2378f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\angig\\anaconda3\\envs\\IA_TraitementDonnees\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5182fa6704640839afedc7712719d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\angig\\anaconda3\\envs\\IA_TraitementDonnees\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\angig\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5adf598ab845dcb4498a0a18872328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614ae6446e1e4f6fa8d097f4a8f37d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c90f46c4c44f4989107bb2b115fa93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e23edbab784483daf1af223d5154f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865aef2b21d544c19d4e4e5c3762727e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffda5792f7d8431b8866efffb71fa1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d1223e752c4cc2820245b3baf3f2ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56c85a6555343c194aa8e4706526c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "838c43139aae4f6db142f038c7c5ed97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc27d0859173462394e30cc9030b7479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e654ec8696fd40979f3a656a3d56567d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/175 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X_emb : (5572, 384)\n",
      "Train emb : (4457, 384)  Test emb : (1115, 384)\n"
     ]
    }
   ],
   "source": [
    "# embedding  permet dettre de convertir du texte en vecteurs denses en utilisant des modèles pré-entraînés.\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modèle léger mais performant\n",
    "emb_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Encodage de tous les SMS en vecteurs denses\n",
    "X_emb = emb_model.encode(\n",
    "    df[\"cleaned_text\"].tolist(),\n",
    "    convert_to_numpy=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "y = df[\"label\"].map({\"ham\": 0, \"spam\": 1}).values\n",
    "\n",
    "print(\"Shape X_emb :\", X_emb.shape)\n",
    "\n",
    "X_train_emb, X_test_emb, y_train_emb, y_test_emb = train_test_split(\n",
    "    X_emb, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "print(\"Train emb :\", X_train_emb.shape, \" Test emb :\", X_test_emb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6dbec80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== SVM (embeddings) (Embeddings) ==========\n",
      "Accuracy : 0.98\n",
      "\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.99       966\n",
      "        spam       0.96      0.89      0.92       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.94      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Matrice de confusion :\n",
      "[[960   6]\n",
      " [ 17 132]]\n",
      "\n",
      "========== MLP (embeddings) (Embeddings) ==========\n",
      "Accuracy : 0.98\n",
      "\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.99       966\n",
      "        spam       0.95      0.89      0.92       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.94      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Matrice de confusion :\n",
      "[[959   7]\n",
      " [ 17 132]]\n"
     ]
    }
   ],
   "source": [
    "#Entraîner SVM et MLP sur ces embeddings\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# SVM sur embeddings\n",
    "svm_emb = LinearSVC()\n",
    "evaluate_model(\"SVM (embeddings)\", svm_emb,\n",
    "               X_train_emb, y_train_emb, X_test_emb, y_test_emb,\n",
    "               results, \"Embeddings\")\n",
    "\n",
    "# MLP sur embeddings\n",
    "mlp_emb = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64),\n",
    "    activation=\"relu\",\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "evaluate_model(\"MLP (embeddings)\", mlp_emb,\n",
    "               X_train_emb, y_train_emb, X_test_emb, y_test_emb,\n",
    "               results, \"Embeddings\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba01c4b",
   "metadata": {},
   "source": [
    "L’utilisation d’embeddings préentraînés (MiniLM) a permis d’évaluer une représentation textuelle plus sémantique que TF-IDF. Les modèles SVM et MLP entraînés sur ces vecteurs denses obtiennent une accuracy de 98 % et un rappel spam de 89 %, ce qui constitue un résultat solide et compétitif. Toutefois, ces performances restent légèrement inférieures à celles des modèles entraînés sur les vecteurs TF-IDF (avec ou sans n-grams), en particulier pour la détection des spams.\n",
    "Cela confirme que, dans ce dataset où les spams reposent sur des indices lexicaux spécifiques (mots rares, termes promotionnels), la représentation TF-IDF demeure plus discriminante que les embeddings généralisés"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5a00c2",
   "metadata": {},
   "source": [
    "#  Rapport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf72ee7",
   "metadata": {},
   "source": [
    "\n",
    "Ce projet avait pour objectif de développer un pipeline complet de classification de SMS afin de distinguer automatiquement les messages spam des messages ham, en comparant deux approches principales : \n",
    "\n",
    "(1) l’utilisation directe des vecteurs TF-IDF et \n",
    "\n",
    "(2) la réduction de dimension par autoencoder suivie de modèles de classification classiques.\n",
    "\n",
    "Les expérimentations montrent que les modèles entraînés sur les vecteurs TF-IDF bruts offrent les meilleures performances. Le SVM linéaire atteint une accuracy de 99 %, un rappel spam de 90 % et un F1-score de 94 %, en faisant le modèle le plus performant du projet. Le MLP obtient des résultats très proches (98 % d’accuracy), confirmant que les modèles supervisés exploitent efficacement la richesse lexicale des 5000 dimensions TF-IDF.\n",
    "\n",
    "À l’inverse, la réduction de dimension par autoencoder entraîne une perte d’information significative. Dans l’espace latent à 128 dimensions, le meilleur modèle (MLP) n’atteint qu’un rappel spam de 70 %, ce qui reste nettement inférieur aux performances obtenues avec les données complètes. Ceci confirme que la capacité à détecter les spams dépend directement de la richesse lexicale conservée : les spams reposent souvent sur des mots rares et fortement discriminants (free, winner, claim, etc.), que la compression a tendance à lisser ou à supprimer.\n",
    "\n",
    "Au-delà de cette comparaison de base, plusieurs pistes d’amélioration ont été explorées. L’enrichissement TF-IDF avec des n-grams (1,2) améliore légèrement le rappel du SVM (0,91), tandis que l’utilisation de class_weight=\"balanced\" augmente fortement la sensibilité de la régression logistique, dont le rappel spam passe de 0,73 à 0,92. Les embeddings préentraînés (Sentence-BERT MiniLM) offrent des performances solides (accuracy 0,98 ; rappel spam 0,89), mais restent légèrement inférieurs à TF-IDF pour ce corpus fortement lexical.\n",
    "\n",
    "Ces résultats montrent qu’il est possible d’affiner le pipeline et de renforcer la détection du spam, tout en confirmant la robustesse de l’approche TF-IDF + SVM comme solution optimale pour ce problème de classification de SMS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IA_TraitementDonnees",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
